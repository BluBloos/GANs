{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNlh36IjXU1T18pepR5FfW+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BluBloos/QMIND2020-2021/blob/main/MNIST_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runtime Verification and Google Drive Mount"
      ],
      "metadata": {
        "id": "aUExwjMY0Y3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrbsyQGc0iEU",
        "outputId": "9a9b296a-ff39-4759-ee27-ec250f9bdd5a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/drive/My\\ Drive/foo.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2i3reyn0irO",
        "outputId": "5bb19c14-ed02-4532-b36c-78ee08f1b7b3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Google Drive!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEM0MZqn0mNE",
        "outputId": "97bf2158-844a-4355-aaaa-b17dfd8f3408"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec  8 20:57:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    33W / 250W |   2625MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXa82bfE0n_9",
        "outputId": "266657d9-8792-45ed-8747-23a4525945c2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "QR9fIXNRxYFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# just a bunch of imports\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from IPython import display\n",
        "import math\n",
        "############################"
      ],
      "metadata": {
        "id": "9IjH32OWxaDM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import MNIST Data"
      ],
      "metadata": {
        "id": "1RxEEDdkxiaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "print(\"Train Images: {}\".format(train_images.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzEI9AtJxdfF",
        "outputId": "57f1dfd8-b717-4709-e47d-e8deb3969406"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images: (60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "GmjzTVGyxo0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 500\n",
        "total_batch_size = train_images.shape[0]\n",
        "m = 256 # BATCH SIZE\n",
        "noise_dim = 100\n",
        "examples = 16\n",
        "seed = tf.random.normal(shape=[examples, noise_dim])\n"
      ],
      "metadata": {
        "id": "_quYtAtXxhPM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Dataset"
      ],
      "metadata": {
        "id": "33MFh6LmxwIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the batched dataset\n",
        "train_images = train_images.reshape(total_batch_size, 28, 28, 1).astype('float32')\n",
        " # Normalize the images to [-1, 1] to match the output of the generator (tanh activation)\n",
        "train_images = (train_images - 127.5) / 127.5\n",
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "train_dataset = train_dataset.shuffle(total_batch_size)\n",
        "train_dataset = train_dataset.batch(m, drop_remainder=True)\n"
      ],
      "metadata": {
        "id": "gEhMZ_sGxx-6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "OV3Tg5azx5G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Generator model is very diff from ours!\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    # NOTE: use_bias just means whether there is a bias vector in computing the layer outputs\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(noise_dim,)))\n",
        "    # What's going on with Batch norm?\n",
        "    '''\n",
        "    Applies a transformation that maintains the mean output close to 0 and the output\n",
        "    standard deviation close to 1. Stablizes training. Still don't know how it works fully.\n",
        "    '''\n",
        "    model.add(layers.BatchNormalization())\n",
        "    # So what's going on with the leaky relu?\n",
        "    '''\n",
        "    f(x) = alpha (0.3) * x if x < 0\n",
        "    f(x) = x if x >= 0\n",
        "    '''\n",
        "    # It allows a small gradient when the unit is not active,\n",
        "    # regular relu is a linear pass thru w/ all negative units truncated to zero\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    #assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    #assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    #assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    #assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = make_generator_model()\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgNechCCx6mt",
        "outputId": "eeb4a697-de52-426d-c78b-37da2b318d38"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 12544)             1254400   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 12544)            50176     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 12544)             0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 7, 7, 128)        819200    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 14, 14, 64)       204800    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 1)        1600      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,330,944\n",
            "Trainable params: 2,305,472\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator Test"
      ],
      "metadata": {
        "id": "RR-v1JY-yJ4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the generator!\n",
        "noise = tf.random.normal([1, noise_dim])\n",
        "generated_image = generator(noise, training=False)\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6WJt2X90yL1U",
        "outputId": "319bdc3b-8ad7-4a62-e2f1-e875f2da0198"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f750856c390>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator Model"
      ],
      "metadata": {
        "id": "_GRqU0hZyQg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: The discriminator model is also different!\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    '''\n",
        "    Kernel size of 5x5, stride of 2x2, 64 learned filters\n",
        "    '''\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    '''\n",
        "    Dropout only applies during training, randomly drops units. used\n",
        "    to simulate multiple network architectures for fixing overfitting\n",
        "    '''\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    #NOTE: There is no activation at the end of this! This means the data is raw\n",
        "    # and not in the [0, 1] range, which means it can be termed \"logit\"\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "    \n",
        "discriminator = make_discriminator_model()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbIeCzHAySHK",
        "outputId": "f327485f-600b-4524-961c-e3400f4be06d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 14, 14, 64)        1664      \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descrim test"
      ],
      "metadata": {
        "id": "nRMVtuSYyW65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-HlJRhmyYr0",
        "outputId": "81354ae5-1d7c-421f-af7d-e58548b47409"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.00329705]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loss functions"
      ],
      "metadata": {
        "id": "caASCN5rymT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# This method returns a helper function to compute cross entropy loss\n",
        "# NOTE: From_logits=true means to assume that y_pred is a tensor of logits\n",
        "'''\n",
        "In maths, logit is a function that maps probabilities of [0, 1] to (-inf, inf).\n",
        "Note that this is the inverse of the sigmoid function.\n",
        "L = ln ( p / (1-p) )\n",
        "In tensorflow it means to say the thing that is to be mapped to 0 -> 1 ?\n",
        "'''\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Recall, discriminator wants to maximize log (D(x)) + log(1-D(G(z)))\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    # -log(real_output)\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    # -log(1-fake_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    # total_loss = - [ log(real_output) + log(1 - fake_output) ]\n",
        "    # We can then agree that this loss function will maximize the loss\n",
        "    # function as seen in the paper!\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    # -log(fake_output)\n",
        "    # We can then agree that this loss function will maximize log(D(G(z)))\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "'''\n",
        "BIG NOTE: From logits is true, so for our custom loss functions we must apply sigmoid\n",
        "'''\n",
        "\n",
        "# the discriminator wants to maximize log(D(x)) + log(1-D(G(z)))\n",
        "def discriminator_loss2(real_output, fake_output):\n",
        "    #small_tensor_1 = tf.constant(tf.keras.backend.epsilon(), dtype=tf.float32, shape=fake_output.shape)\n",
        "    #small_tensor_2 = tf.constant(tf.keras.backend.epsilon(), dtype=tf.float32, shape=real_output.shape)\n",
        "    loss = tf.math.log(tf.math.sigmoid(real_output)) + tf.math.log1p(-tf.math.sigmoid(fake_output))\n",
        "    loss = tf.math.reduce_mean(loss)\n",
        "    return -loss;\n",
        "\n",
        "# the generator wants to maximize log(D(G(z)))\n",
        "def generator_loss2(fake_output):\n",
        "    #small_tensor = tf.constant(tf.keras.backend.epsilon(), dtype=tf.float32, shape=fake_output.shape)\n",
        "    # apply log to fake_output element-wise\n",
        "\n",
        "    loss = tf.math.log(tf.math.sigmoid(fake_output))\n",
        "    # adds up all the elements then divides by m\n",
        "    loss = tf.math.reduce_mean(loss)\n",
        "    return -loss;"
      ],
      "metadata": {
        "id": "qoH1sM_aykJ9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## optimizers"
      ],
      "metadata": {
        "id": "cbUS0TFzzDyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Different optimizers are used\n",
        "'''\n",
        "TODO: Investigate the Adam optimizer\n",
        "'''\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "KTGf0y55zE8G"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Algo"
      ],
      "metadata": {
        "id": "fDZtEItFzIkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/GAN-OUT/'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "# NOTE: The training step is different\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([m, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      #gen_loss = generator_loss(fake_output)\n",
        "      #disc_loss = discriminator_loss(real_output, fake_output)\n",
        "      gen_loss = generator_loss2(fake_output)\n",
        "      disc_loss = discriminator_loss2(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    #gradients_of_generator = [-x for x in gradients_of_generator]\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    #gradients_of_discriminator = [-x for x in gradients_of_discriminator]\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "_fW9JJovzLk5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## helper functions"
      ],
      "metadata": {
        "id": "ZHEJoDdKzUuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FIG_DIR = '/content/drive/My Drive/GAN-OUT/'\n",
        "\n",
        "def generate_and_save_images(save=False, show=True, uid=0):\n",
        "    # BIG NOTE: The whole idea of these models is that they can do operations in parallel. This is the whole idea of batching,\n",
        "    # and this is why in the summary the shapes all look like (None, ....), because the first tensor shape can be anything!\n",
        "    # NOTE: In python it is possible to make class instances callable by overdding __call__. The training param\n",
        "    # is used to make sure that the model computes like it would during training. Ex) Dropout is only applied during\n",
        "    # the training phase.\n",
        "    fake_images = generator(seed, training=False)\n",
        "    #print(\"fake_images shape: {}\".format(fake_images.shape))\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    for i in range(fake_images.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        # Note that cmap maps from the [0, 1] range\n",
        "        plt.imshow(fake_images[i, :, :, 0], cmap='gray')\n",
        "        if save:\n",
        "            plt.savefig(FIG_DIR + \"Images/\" + str(uid) + \".png\")\n",
        "    if show:\n",
        "        plt.show()\n",
        "    # clear the plot, so that all of them do not show at the end!\n",
        "    plt.close()\n",
        "\n",
        "def disc_accuracy():\n",
        "    real_accuracy = 0\n",
        "    fake_accuracy = 0\n",
        "\n",
        "    better_test_images = test_images[0 : m, :, :]\n",
        "    better_test_images = better_test_images.reshape(m, 28, 28, 1)\n",
        "\n",
        "    noise = tf.random.normal([m, noise_dim])\n",
        "    generated_images = generator(noise, training=False)\n",
        "    real_output = discriminator(better_test_images, training=False)\n",
        "    fake_output = discriminator(generated_images, training=False)\n",
        "\n",
        "    arr = real_output.numpy()\n",
        "    for x in arr:\n",
        "        elem = x[0]\n",
        "        if elem > 0.5:\n",
        "            real_accuracy += 1\n",
        "    # Note: The len(arr) should be equal to m\n",
        "    real_accuracy = real_accuracy / len(arr)\n",
        "\n",
        "    arr = fake_output.numpy()\n",
        "    for x in arr:\n",
        "        elem = x[0]\n",
        "        if elem <= 0.5:\n",
        "            fake_accuracy += 1\n",
        "    # Note: The len(arr) should be equal to m\n",
        "    fake_accuracy = fake_accuracy / len(arr)\n",
        "\n",
        "    return (real_accuracy, fake_accuracy)\n",
        "\n",
        "def test_losses():\n",
        "    # Compute the loss function for a bunch of batches, then average the loss function!\n",
        "    disc_loss = tf.constant(0, dtype=tf.float32)\n",
        "    gen_loss = tf.constant(0, dtype=tf.float32)\n",
        "\n",
        "    for image_batch in train_dataset:\n",
        "        noise = tf.random.normal([m, noise_dim])\n",
        "        generated_images = generator(noise, training=False)\n",
        "        real_output = discriminator(image_batch, training=False)\n",
        "        fake_output = discriminator(generated_images, training=False)\n",
        "        disc_loss += discriminator_loss(real_output, fake_output)\n",
        "        gen_loss += generator_loss(fake_output)\n",
        "\n",
        "    disc_loss = disc_loss / math.floor(60000 / m)\n",
        "    gen_loss = gen_loss / math.floor(60000 / m)\n",
        "\n",
        "    return (disc_loss, gen_loss)"
      ],
      "metadata": {
        "id": "Rr8UMHxNzWJ-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train loop"
      ],
      "metadata": {
        "id": "phdaJAFUzctJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#####################\n",
        "# Variables for history of loss and discriminator accuracy\n",
        "a1_hist = []\n",
        "a2_hist = []\n",
        "d_hist = []\n",
        "g_hist = []\n",
        "#####################\n",
        "\n",
        "# Maybe one of the only things that is still the same is this part of the code!\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    print(\"Starting epoch {}\".format(epoch + 1))\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(save=True, show=False, uid=epoch)\n",
        "\n",
        "    # Save the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "    print(\"Testing accuracy and recording loss!\")\n",
        "    start = time.time()\n",
        "\n",
        "    a_real, a_fake = disc_accuracy()\n",
        "    a1_hist.append(a_real)\n",
        "    a2_hist.append(a_fake)\n",
        "\n",
        "    disc_loss, gen_loss = test_losses()\n",
        "    d_hist.append(disc_loss)\n",
        "    g_hist.append(gen_loss)\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Done in {} seconds!\".format(end-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(save=True, show=False, uid=epoch)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT_s-_ekzeIe",
        "outputId": "d1db6b81-b0a6-448e-c0da-c036eeeef246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 43 is 9.978853225708008 sec\n",
            "Testing accuracy and recording loss!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## post training fun"
      ],
      "metadata": {
        "id": "p-IWt81T0BLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d_hist, g_hist, a1_hist, a2_hist):\n",
        "\t# plot loss\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(d_hist, label='disc')\n",
        "    plt.plot(g_hist, label='gen')\n",
        "    plt.legend()\n",
        "\n",
        "\t# plot discriminator accuracy\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(a1_hist, label='acc-real')\n",
        "    plt.plot(a2_hist, label='acc-fake')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "plot_history(d_hist, g_hist, a1_hist, a2_hist)\n",
        "\n",
        "#######################\n",
        "# generate the gif\n",
        "print(\"Generating the GIF!\")\n",
        "png_dir = './Images/'\n",
        "images = []\n",
        "for file_name in os.listdir(png_dir):\n",
        "    if file_name.endswith('.png'):\n",
        "        file_path = os.path.join(png_dir, file_name)\n",
        "        images.append(imageio.imread(file_path))\n",
        "imageio.mimsave('Images/movie.gif', images)\n",
        "#################"
      ],
      "metadata": {
        "id": "aQglrE4x0Czx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}